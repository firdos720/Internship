{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0077b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15335e67",
   "metadata": {},
   "source": [
    "1. Scrape  the  details  of  most  viewed  videos  on  YouTube  from  Wikipedia.  \n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:  A) \n",
    "Rank   \n",
    "B) Name   \n",
    "C) Artist   \n",
    "D) Upload date   \n",
    "E) Views   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ed12c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "url=' https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos '\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3dd38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "artist=[]\n",
    "date=[]\n",
    "views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1f9f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "for i in n:\n",
    "    name.append(i.text)\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "for i in a:\n",
    "    artist.append(i.text)\n",
    "d=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "for i in d:\n",
    "    date.append(i.text)\n",
    "v=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "for i in v:\n",
    "    views.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "79bacd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Shape of You\"[20]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"[23]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Learning Colors ‚Äì Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Masha and the Bear ‚Äì Recipe for Disaster\"[38]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Sugar\"[40]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Sorry\"[46]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[47]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name  \\\n",
       "0                             \"Baby Shark Dance\"[7]   \n",
       "1                                   \"Despacito\"[10]   \n",
       "2                        \"Johny Johny Yes Papa\"[18]   \n",
       "3                                   \"Bath Song\"[19]   \n",
       "4                                \"Shape of You\"[20]   \n",
       "5                               \"See You Again\"[23]   \n",
       "6                           \"Wheels on the Bus\"[28]   \n",
       "7                 \"Phonics Song with Two Words\"[29]   \n",
       "8                                 \"Uptown Funk\"[30]   \n",
       "9                               \"Gangnam Style\"[31]   \n",
       "10  \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[36]   \n",
       "11                             \"Dame Tu Cosita\"[37]   \n",
       "12   \"Masha and the Bear ‚Äì Recipe for Disaster\"[38]   \n",
       "13                                     \"Axel F\"[39]   \n",
       "14                                      \"Sugar\"[40]   \n",
       "15                        \"Baa Baa Black Sheep\"[41]   \n",
       "16                             \"Counting Stars\"[42]   \n",
       "17                             \"Lakdi Ki Kathi\"[43]   \n",
       "18                                       \"Roar\"[44]   \n",
       "19           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "20                                      \"Sorry\"[46]   \n",
       "21                      \"Shree Hanuman Chalisa\"[47]   \n",
       "22          \"Humpty the train on a fruits ride\"[48]   \n",
       "23                          \"Thinking Out Loud\"[49]   \n",
       "24                                    \"Perfect\"[50]   \n",
       "25                                 \"Dark Horse\"[51]   \n",
       "26                                 \"Let Her Go\"[52]   \n",
       "27                                      \"Faded\"[53]   \n",
       "28                             \"Girls Like You\"[54]   \n",
       "29                                    \"Lean On\"[55]   \n",
       "\n",
       "                                               Artist               Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                                 Psy      July 15, 2012   \n",
       "10                                        Miroshka TV  February 27, 2018   \n",
       "11                                      Ultra Records      April 5, 2018   \n",
       "12                                         Get Movies   January 31, 2012   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "16                                        OneRepublic       May 31, 2013   \n",
       "17                                       Jingle Toons      June 14, 2018   \n",
       "18                                         Katy Perry  September 5, 2013   \n",
       "19                                            Shakira       June 4, 2010   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                                         Ed Sheeran    October 7, 2014   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                         Katy Perry  February 20, 2014   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                        Alan Walker   December 3, 2015   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "0   14.32  \n",
       "1    8.41  \n",
       "2    6.89  \n",
       "3    6.66  \n",
       "4    6.23  \n",
       "5    6.22  \n",
       "6    6.01  \n",
       "7    5.75  \n",
       "8    5.18  \n",
       "9    5.10  \n",
       "10   5.09  \n",
       "11   4.59  \n",
       "12   4.57  \n",
       "13   4.45  \n",
       "14   4.02  \n",
       "15   4.01  \n",
       "16   4.00  \n",
       "17   3.98  \n",
       "18   3.98  \n",
       "19   3.89  \n",
       "20   3.78  \n",
       "21   3.77  \n",
       "22   3.76  \n",
       "23   3.75  \n",
       "24   3.70  \n",
       "25   3.70  \n",
       "26   3.64  \n",
       "27   3.60  \n",
       "28   3.58  \n",
       "29   3.57  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':name,'Artist':artist,'Date':date,'Views':views})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80005f05",
   "metadata": {},
   "source": [
    "2. Scrape the details team India‚Äôs international fixtures from bcci.tv.   \n",
    "Url = https://www.bcci.tv/.   \n",
    "You need to find following details:   \n",
    "A) Series   \n",
    "B) Place   \n",
    "C) Date   \n",
    "D) Time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d422afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "url=' https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3abc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b247bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tags=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in s_tags:\n",
    "    Series.append(i.text)\n",
    "p=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in p:\n",
    "    Place.append(i.text)\n",
    "d=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in d:\n",
    "    Date.append(i.text)\n",
    "t=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in t:\n",
    "    Time.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d144a7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>2 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>6 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>9 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>5 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>9 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>12 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>15 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Series  \\\n",
       "0  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "1  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "2  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "3                     ICC MENS T20 WORLD CUP 2024   \n",
       "4                     ICC MENS T20 WORLD CUP 2024   \n",
       "5                     ICC MENS T20 WORLD CUP 2024   \n",
       "6                     ICC MENS T20 WORLD CUP 2024   \n",
       "7                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "8                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                               Place           Date  \\\n",
       "0              Sylhet International Cricket Stadium,    2 MAY, 2024   \n",
       "1              Sylhet International Cricket Stadium,    6 MAY, 2024   \n",
       "2              Sylhet International Cricket Stadium,    9 MAY, 2024   \n",
       "3       Nassau County International Cricket Stadium,   5 JUNE, 2024   \n",
       "4       Nassau County International Cricket Stadium,   9 JUNE, 2024   \n",
       "5       Nassau County International Cricket Stadium,  12 JUNE, 2024   \n",
       "6  Central Broward Park & Broward County Stadium,...  15 JUNE, 2024   \n",
       "7                                Harare Sports Club,   6 JULY, 2024   \n",
       "8                                Harare Sports Club,   7 JULY, 2024   \n",
       "\n",
       "          Time  \n",
       "0  3:30 PM IST  \n",
       "1  3:30 PM IST  \n",
       "2  3:30 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  \n",
       "6  8:00 PM IST  \n",
       "7  8:00 PM IST  \n",
       "8  8:00 PM IST  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Series':Series,'Place':Place,\"Date\":Date,'Time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4469e00d",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.   \n",
    "Url = http://statisticstimes.com/   \n",
    "You have to find following details: A) Rank   \n",
    "B) State   \n",
    "C) GSDP(18-19)- at current prices   \n",
    "D) GSDP(19-20)- at current prices   \n",
    "E) Share(18-19)   \n",
    "F) GDP($ billion)   \n",
    "Note: - From statisticstimes home page you have to reach to economy page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5930505",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "url=' http://statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29580155",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "state=[]\n",
    "gsdp1=[]\n",
    "gsdp2=[]\n",
    "share=[]\n",
    "gdp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ada53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=driver.find_elements(By.XPATH,'//td[@class=\"data1\"]')\n",
    "for i in r:\n",
    "    rank.append(i.text)\n",
    "s=driver.find_elements(By.XPATH,'//td[@class=\"name\"]')\n",
    "for i in s:\n",
    "    state.append(i.text)\n",
    "g1=driver.find_elements(By.XPATH,'//td[4][@class=\"data\"]')\n",
    "for i in g1:\n",
    "    gsdp1.append(i.text)\n",
    "g2=driver.find_elements(By.XPATH,'//td[9][@class=\"data\"]')\n",
    "for i in g2:\n",
    "    gsdp2.append(i.text)\n",
    "s=driver.find_elements(By.XPATH,'//td[6][@class=\"data\"]')\n",
    "for i in s:\n",
    "    share.append(i.text)\n",
    "g3=driver.find_elements(By.XPATH,'//td[7][@class=\"data\"]')\n",
    "for i in g3:\n",
    "    gdp.append(i.text)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cda493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 136 136 136 136 136\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(state),len(gsdp1),len(gsdp2),len(share),len(gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "286e6c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RAnk</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP1</th>\n",
       "      <th>GSDP2</th>\n",
       "      <th>Shares</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>35,643</td>\n",
       "      <td>18,993</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>39,630</td>\n",
       "      <td>21,085</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>35,555</td>\n",
       "      <td>17,196</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>30,957</td>\n",
       "      <td>13,222</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>15,847</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>6,558</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td></td>\n",
       "      <td>India</td>\n",
       "      <td>23,439,442</td>\n",
       "      <td>12,872,132</td>\n",
       "      <td></td>\n",
       "      <td>14,805,736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RAnk                      State       GSDP1       GSDP2 Shares         GDP\n",
       "0     33  Andaman & Nicobar Islands           -           -  0.04%       1.385\n",
       "1     32                    Mizoram           -           -  0.12%       3.715\n",
       "2     31                   Nagaland      35,643      18,993  0.13%       4.144\n",
       "3     30          Arunachal Pradesh      39,630      21,085  0.15%       4.643\n",
       "4     29                    Manipur           -           -  0.16%       4.885\n",
       "..   ...                        ...         ...         ...    ...         ...\n",
       "131   30          Arunachal Pradesh      35,555      17,196  0.15%           -\n",
       "132   31                   Nagaland      30,957      13,222  0.13%           -\n",
       "133   32                    Mizoram           -      15,847  0.12%           -\n",
       "134   33  Andaman & Nicobar Islands           -       6,558  0.04%           -\n",
       "135                           India  23,439,442  12,872,132         14,805,736\n",
       "\n",
       "[136 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame({'RAnk':rank,'State':state,'GSDP1':gsdp1,'GSDP2':gsdp2,'Shares':share,'GDP':gdp})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b398e5",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.   \n",
    "Url = https://github.com/   \n",
    "You have to find the following details:   \n",
    "A) Repository title   \n",
    "B) Repository description   \n",
    "C) Contributors count   \n",
    "D) Language used  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c7ea8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://github.com/search?q=trending%20repositories&type=repositories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54d176e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "desc=[]\n",
    "c_count=[]\n",
    "lang=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7459f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url=[]\n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"Link__StyledLink-sc-14289xe-0 dheQRw\"]')\n",
    "for i in url:\n",
    "    data_url.append(i.get_attribute('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24129b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/QasimWani/LeetHub',\n",
       " 'https://github.com/Semigradsky/trending-repositories',\n",
       " 'https://github.com/laowch/GithubTrends',\n",
       " 'https://github.com/vitalets/github-trending-repos',\n",
       " 'https://github.com/mbadry1/Trending-Deep-Learning',\n",
       " 'https://github.com/zhuowenli/githuber',\n",
       " 'https://github.com/ophobe/trending',\n",
       " 'https://github.com/alidehkhodaei/trending-repositories',\n",
       " 'https://github.com/andygrunwald/go-trending',\n",
       " 'https://github.com/ecrmnn/trending-github']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db7cbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "desc=[]\n",
    "c_count=[]\n",
    "lang=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb3cd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in data_url:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    t=driver.find_elements(By.XPATH,'//span[@class=\"author flex-self-stretch\"]')\n",
    "    for i in t:\n",
    "        title.append(i.text)\n",
    "    d=driver.find_elements(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "    for i in d:\n",
    "        desc.append(i.text)\n",
    "    \n",
    "    l=driver.find_elements(By.XPATH,'//span[2][@class=\"color-fg-default text-bold mr-1\"]')\n",
    "    for i in l:\n",
    "        lang.append(i.text)\n",
    "                          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c509fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(desc),len(lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "540b7103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Description</th>\n",
       "      <th>languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QasimWani</td>\n",
       "      <td>Automatically sync your leetcode solutions to ...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semigradsky</td>\n",
       "      <td>‚≠ê This is a list of repositories that were tre...</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laowch</td>\n",
       "      <td>It's a GitHub Trending repositories Viewer wit...</td>\n",
       "      <td>CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vitalets</td>\n",
       "      <td>Track GitHub trending repositories in your fav...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mbadry1</td>\n",
       "      <td>Top 100 trending deep learning repositories so...</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zhuowenli</td>\n",
       "      <td>Display Github Trending repositories on Chrome...</td>\n",
       "      <td>Batchfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ophobe</td>\n",
       "      <td>Dataset of trending repositories on GitHub</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alidehkhodaei</td>\n",
       "      <td>A bot that automatically fetches trending repo...</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>andygrunwald</td>\n",
       "      <td>Go library for accessing trending repositories...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ecrmnn</td>\n",
       "      <td>üìà  Simple API for getting trending repositorie...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QasimWani</td>\n",
       "      <td>Automatically sync your leetcode solutions to ...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Semigradsky</td>\n",
       "      <td>‚≠ê This is a list of repositories that were tre...</td>\n",
       "      <td>Vue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>laowch</td>\n",
       "      <td>It's a GitHub Trending repositories Viewer wit...</td>\n",
       "      <td>Sass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vitalets</td>\n",
       "      <td>Track GitHub trending repositories in your fav...</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mbadry1</td>\n",
       "      <td>Top 100 trending deep learning repositories so...</td>\n",
       "      <td>SCSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>zhuowenli</td>\n",
       "      <td>Display Github Trending repositories on Chrome...</td>\n",
       "      <td>CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ophobe</td>\n",
       "      <td>Dataset of trending repositories on GitHub</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>alidehkhodaei</td>\n",
       "      <td>A bot that automatically fetches trending repo...</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>andygrunwald</td>\n",
       "      <td>Go library for accessing trending repositories...</td>\n",
       "      <td>Makefile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ecrmnn</td>\n",
       "      <td>üìà  Simple API for getting trending repositorie...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                                        Description  \\\n",
       "0       QasimWani  Automatically sync your leetcode solutions to ...   \n",
       "1     Semigradsky  ‚≠ê This is a list of repositories that were tre...   \n",
       "2          laowch  It's a GitHub Trending repositories Viewer wit...   \n",
       "3        vitalets  Track GitHub trending repositories in your fav...   \n",
       "4         mbadry1  Top 100 trending deep learning repositories so...   \n",
       "5       zhuowenli  Display Github Trending repositories on Chrome...   \n",
       "6          ophobe         Dataset of trending repositories on GitHub   \n",
       "7   alidehkhodaei  A bot that automatically fetches trending repo...   \n",
       "8    andygrunwald  Go library for accessing trending repositories...   \n",
       "9          ecrmnn  üìà  Simple API for getting trending repositorie...   \n",
       "10      QasimWani  Automatically sync your leetcode solutions to ...   \n",
       "11    Semigradsky  ‚≠ê This is a list of repositories that were tre...   \n",
       "12         laowch  It's a GitHub Trending repositories Viewer wit...   \n",
       "13       vitalets  Track GitHub trending repositories in your fav...   \n",
       "14        mbadry1  Top 100 trending deep learning repositories so...   \n",
       "15      zhuowenli  Display Github Trending repositories on Chrome...   \n",
       "16         ophobe         Dataset of trending repositories on GitHub   \n",
       "17  alidehkhodaei  A bot that automatically fetches trending repo...   \n",
       "18   andygrunwald  Go library for accessing trending repositories...   \n",
       "19         ecrmnn  üìà  Simple API for getting trending repositorie...   \n",
       "\n",
       "     languages  \n",
       "0   JavaScript  \n",
       "1         HTML  \n",
       "2          CSS  \n",
       "3   JavaScript  \n",
       "4        Shell  \n",
       "5    Batchfile  \n",
       "6         Java  \n",
       "7         HTML  \n",
       "8   JavaScript  \n",
       "9       Python  \n",
       "10  JavaScript  \n",
       "11         Vue  \n",
       "12        Sass  \n",
       "13        HTML  \n",
       "14        SCSS  \n",
       "15         CSS  \n",
       "16      Kotlin  \n",
       "17          Go  \n",
       "18    Makefile  \n",
       "19  TypeScript  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'title':title,'Description':desc,'languages':lang})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca52540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2a79e2a",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/  You have to find the \n",
    "following details:   \n",
    "A) Song name   \n",
    "B) Artist name   \n",
    "C) Last week rank   \n",
    "D) Peak rank   \n",
    "E) Weeks on board   \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e7eb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https:/www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c846053",
   "metadata": {},
   "outputs": [],
   "source": [
    "song=[]\n",
    "artist=[]\n",
    "rank=[]\n",
    "prank=[]\n",
    "week=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e87b3ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet\"]')\n",
    "for i in r:\n",
    "    rank.append(i.text)\n",
    "\n",
    "try:\n",
    "    s=driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "    for i in s:\n",
    "        song.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    song.append('-')\n",
    "        \n",
    "\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in a:\n",
    "    artist.append(i.text)\n",
    "p=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"]/span')\n",
    "for i in p:\n",
    "    prank.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f40f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f9f8203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 99 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(artist),len(song),len(rank),len(prank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1a8a888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Down Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>I Can Do It With A Broken Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>The Tortured Poets Department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>So Long, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>My Boy Only Breaks His Favorite Toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>$uicideBoy$</td>\n",
       "      <td>Us Vs. Them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Tucker Wetmore</td>\n",
       "      <td>Wine Into Whiskey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>Spin You Around (1/24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>310babii</td>\n",
       "      <td>Soak City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Justin Timberlake</td>\n",
       "      <td>Selfish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Artist                                  song\n",
       "0        Taylor Swift                              Down Bad\n",
       "1        Taylor Swift       I Can Do It With A Broken Heart\n",
       "2        Taylor Swift         The Tortured Poets Department\n",
       "3        Taylor Swift                       So Long, London\n",
       "4        Taylor Swift  My Boy Only Breaks His Favorite Toys\n",
       "..                ...                                   ...\n",
       "94        $uicideBoy$                           Us Vs. Them\n",
       "95     Tucker Wetmore                     Wine Into Whiskey\n",
       "96      Morgan Wallen                Spin You Around (1/24)\n",
       "97           310babii                             Soak City\n",
       "98  Justin Timberlake                               Selfish\n",
       "\n",
       "[99 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Artist':artist,'song':song})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30530826",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.   \n",
    "A) Book name   \n",
    "B) Author name   \n",
    "C) Volumes sold   \n",
    "D) Publisher   \n",
    "E) Genre   \n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac527ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(' https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7e6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "author=[]\n",
    "sold=[]\n",
    "publisher=[]\n",
    "genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a073358",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=driver.find_elements(By.XPATH,'//td[2][@class=\"left\"]')\n",
    "for i in n:\n",
    "    name.append(i.text)\n",
    "a=driver.find_elements(By.XPATH,'//td[3][@class=\"left\"]')\n",
    "for i in a:\n",
    "    author.append(i.text)\n",
    "s=driver.find_elements(By.XPATH,'//td[4][@class=\"left\"]')\n",
    "for i in s:\n",
    "    sold.append(i.text)\n",
    "p=driver.find_elements(By.XPATH,'//td[5][@class=\"left\"]')\n",
    "for i in p:\n",
    "    publisher.append(i.text)\n",
    "g=driver.find_elements(By.XPATH,'//td[@class=\"last left\"]')\n",
    "for i in g:\n",
    "    genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a362fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bookname</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Publishe</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Bookname       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "        Sales         Publishe                        Genre  \n",
       "0   5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1   4,475,152       Bloomsbury           Children's Fiction  \n",
       "2   4,200,654       Bloomsbury           Children's Fiction  \n",
       "3   4,179,479       Bloomsbury           Children's Fiction  \n",
       "4   3,758,936     Random House              Romance & Sagas  \n",
       "..        ...              ...                          ...  \n",
       "95    807,311     Random House   General & Literary Fiction  \n",
       "96    794,201          Penguin        Food & Drink: General  \n",
       "97    792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98    791,507            Orion           Biography: General  \n",
       "99    791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.DataFrame({'Bookname':name,'Author_name':author,'Sales':sold,'Publishe':publisher,'Genre':genre})\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032af29",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.   \n",
    "Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "to find the following details:   \n",
    "A) Name   \n",
    "B) Year span   \n",
    "C) Genre   \n",
    "D) Run time   \n",
    "E) Ratings   \n",
    "F) Votes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc9ac839",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.imdb.com/list/ls512407256/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b81a8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "year=[]\n",
    "genre=[]\n",
    "time=[]\n",
    "ratings=[]\n",
    "votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa3dfaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]')\n",
    "for i in n:\n",
    "    name.append(i.text)\n",
    "y=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "for i in y:\n",
    "    year.append(i.text)\n",
    "g=driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in g:\n",
    "    genre.append(i.text)\n",
    "t=driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in t:\n",
    "    time.append(i.text)\n",
    "r=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]/div/span[2]')\n",
    "for i in r:\n",
    "    ratings.append(i.text)\n",
    "v=driver.find_elements(By.XPATH,'//p[4][@class=\"text-muted text-small\"]/span[2]')\n",
    "for i in v:\n",
    "    votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96396af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>time</th>\n",
       "      <th>ratings</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011‚Äì2019)</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>60 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,285,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016‚Äì2025)</td>\n",
       "      <td>(2016‚Äì2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,336,942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010‚Äì2022)</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,082,474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017‚Äì2020)</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>315,621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014‚Äì2020)</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>276,193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. True Detective (2014‚Äì )</td>\n",
       "      <td>(2014‚Äì )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>656,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. Teen Wolf (2011‚Äì2017)</td>\n",
       "      <td>(2011‚Äì2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>163,297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. The OA (2016‚Äì2019)</td>\n",
       "      <td>(2016‚Äì2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>115,907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. The Simpsons (1989‚Äì )</td>\n",
       "      <td>(1989‚Äì )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>436,042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. Desperate Housewives (2004‚Äì2012)</td>\n",
       "      <td>(2004‚Äì2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>139,806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    names         year  \\\n",
       "0          1. Game of Thrones (2011‚Äì2019)  (2011‚Äì2019)   \n",
       "1          2. Stranger Things (2016‚Äì2025)  (2016‚Äì2025)   \n",
       "2         3. The Walking Dead (2010‚Äì2022)  (2010‚Äì2022)   \n",
       "3           4. 13 Reasons Why (2017‚Äì2020)  (2017‚Äì2020)   \n",
       "4                  5. The 100 (2014‚Äì2020)  (2014‚Äì2020)   \n",
       "..                                    ...          ...   \n",
       "95            96. True Detective (2014‚Äì )     (2014‚Äì )   \n",
       "96              97. Teen Wolf (2011‚Äì2017)  (2011‚Äì2017)   \n",
       "97                 98. The OA (2016‚Äì2019)  (2016‚Äì2019)   \n",
       "98              99. The Simpsons (1989‚Äì )     (1989‚Äì )   \n",
       "99  100. Desperate Housewives (2004‚Äì2012)  (2004‚Äì2012)   \n",
       "\n",
       "                       genre    time ratings      votes  \n",
       "0   Action, Adventure, Drama  60 min     9.2  2,285,600  \n",
       "1     Drama, Fantasy, Horror  60 min     8.7  1,336,942  \n",
       "2    Drama, Horror, Thriller  45 min     8.1  1,082,474  \n",
       "3   Drama, Mystery, Thriller  60 min     7.5    315,621  \n",
       "4     Drama, Mystery, Sci-Fi  43 min     7.6    276,193  \n",
       "..                       ...     ...     ...        ...  \n",
       "95     Crime, Drama, Mystery  60 min     8.9    656,800  \n",
       "96    Action, Drama, Fantasy  41 min     7.7    163,297  \n",
       "97   Drama, Fantasy, Mystery  60 min     7.8    115,907  \n",
       "98         Animation, Comedy  22 min     8.7    436,042  \n",
       "99    Comedy, Drama, Mystery  45 min     7.6    139,806  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'names':name,'year':year,'genre':genre,'time':time,'ratings':ratings,'votes':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ab83d",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.   \n",
    "Url = https://archive.ics.uci.edu/  You \n",
    "have to find the following details:   \n",
    "A) Dataset name   \n",
    "B) Data type   \n",
    "C) Task   \n",
    "D) Attribute type   \n",
    "E) No of instances   \n",
    "F) No of attribute G) Year   \n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcaab1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://archive.ics.uci.edu/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "977f2fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url=[]\n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in url:\n",
    "    data_url.append(i.get_attribute('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c89526f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://archive.ics.uci.edu/dataset/53/iris',\n",
       " 'https://archive.ics.uci.edu/dataset/45/heart+disease',\n",
       " 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset',\n",
       " 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik',\n",
       " 'https://archive.ics.uci.edu/dataset/2/adult',\n",
       " 'https://archive.ics.uci.edu/dataset/850/raisin',\n",
       " 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic',\n",
       " 'https://archive.ics.uci.edu/dataset/109/wine',\n",
       " 'https://archive.ics.uci.edu/dataset/186/wine+quality',\n",
       " 'https://archive.ics.uci.edu/dataset/34/diabetes']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efa1b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "data=[]\n",
    "task=[]\n",
    "attr=[]\n",
    "ins=[]\n",
    "na=[]\n",
    "year=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95194782",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in data_url:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    n=driver.find_elements(By.XPATH,'//h1[@class=\"text-3xl font-semibold text-primary-content\"]')\n",
    "    for i in n:\n",
    "        name.append(i.text)\n",
    "    \n",
    "    d=driver.find_elements(By.XPATH,'//p[@class=\"svelte-17wf9gp\"]')\n",
    "    for i in d:\n",
    "        data.append(i.text)\n",
    "    t=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[1]/p')\n",
    "    for i in t:\n",
    "        task.append(i.text)\n",
    "    a=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[3]/p')\n",
    "    for i in a:\n",
    "        attr.append(i.text)\n",
    "    s=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[5]/p')\n",
    "    for i in s:\n",
    "        ins.append(i.text)\n",
    "    \n",
    "    n_a=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[6]/p')\n",
    "    for i in n_a:\n",
    "        na.append(i.text)\n",
    "    try:\n",
    "        y=driver.find_elements(By.XPATH,'//h2[@class=\"text-sm text-primary-content\"]')\n",
    "        for i in y:\n",
    "            year.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        year.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfd06637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 9 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(data),len(task),len(attr),len(year),len(na),len(ins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91141b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Atribute_type</th>\n",
       "      <th>No_of_attr</th>\n",
       "      <th>No_of_instances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>A small classic dataset from Fisher, 1936. One...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>4 databases: Cleveland, Hungary, Switzerland, ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>13</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Images of 13,611 grains of 7 different registe...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>16</td>\n",
       "      <td>13611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>A total of 3810 rice grain's images were taken...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>7</td>\n",
       "      <td>3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>14</td>\n",
       "      <td>48842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Images of the Kecimen and Besni raisin varieti...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>7</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Diagnostic Wisconsin Breast Cancer Database.</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>30</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Using chemical analysis to determine the origi...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>13</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Two datasets are included, related to red and ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>11</td>\n",
       "      <td>4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>This diabetes dataset is from AIM '94</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  \\\n",
       "0                                  Iris   \n",
       "1                         Heart Disease   \n",
       "2                              Dry Bean   \n",
       "3            Rice (Cammeo and Osmancik)   \n",
       "4                                 Adult   \n",
       "5                                Raisin   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)   \n",
       "7                                  Wine   \n",
       "8                          Wine Quality   \n",
       "9                              Diabetes   \n",
       "\n",
       "                                           Data_type  \\\n",
       "0  A small classic dataset from Fisher, 1936. One...   \n",
       "1  4 databases: Cleveland, Hungary, Switzerland, ...   \n",
       "2  Images of 13,611 grains of 7 different registe...   \n",
       "3  A total of 3810 rice grain's images were taken...   \n",
       "4  Predict whether income exceeds $50K/yr based o...   \n",
       "5  Images of the Kecimen and Besni raisin varieti...   \n",
       "6       Diagnostic Wisconsin Breast Cancer Database.   \n",
       "7  Using chemical analysis to determine the origi...   \n",
       "8  Two datasets are included, related to red and ...   \n",
       "9              This diabetes dataset is from AIM '94   \n",
       "\n",
       "                        Task               Atribute_type No_of_attr  \\\n",
       "0                    Tabular              Classification          4   \n",
       "1               Multivariate              Classification         13   \n",
       "2               Multivariate              Classification         16   \n",
       "3               Multivariate              Classification          7   \n",
       "4               Multivariate              Classification         14   \n",
       "5               Multivariate              Classification          7   \n",
       "6               Multivariate              Classification         30   \n",
       "7                    Tabular              Classification         13   \n",
       "8               Multivariate  Classification, Regression         11   \n",
       "9  Multivariate, Time-Series              Classification         20   \n",
       "\n",
       "  No_of_instances  \n",
       "0             150  \n",
       "1             303  \n",
       "2           13611  \n",
       "3            3810  \n",
       "4           48842  \n",
       "5             900  \n",
       "6             569  \n",
       "7             178  \n",
       "8            4898  \n",
       "9               1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'name':name,'Data_type':data,'Task':task,'Atribute_type':attr,'No_of_attr':na,'No_of_instances':ins})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cfd96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
